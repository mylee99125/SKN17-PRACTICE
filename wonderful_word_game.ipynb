{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dcbb32e",
   "metadata": {},
   "source": [
    "# ìœ ì‚¬í•œ ë‹¨ì–´ ì°¾ê¸° ê²Œì„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52676981",
   "metadata": {},
   "source": [
    "1. ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë˜ëŠ” ì ì ˆí•œ ë°ì´í„°ì…‹ì„ ì°¾ëŠ”ë‹¤.\n",
    "2. ì›Œë“œ ì„ë² ë”© ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤.\n",
    "3. ë‹¨ì–´ ìœ ì‚¬ë„ê°€ 0.8 ì´ìƒì¸ A, Bë¥¼ ëœë¤ ì¶”ì¶œí•œë‹¤.\n",
    "4. A, Bì™€ ëŒ€ì‘ë˜ëŠ” Cë¥¼ ì¶”ì¶œí•œë‹¤.\n",
    "5. Dë¥¼ ì…ë ¥ë°›ëŠ”ë‹¤.\n",
    "\n",
    "=>\n",
    "A:B = C:D ê´€ê³„ì— ëŒ€ì‘í•˜ëŠ” Dë¥¼ ì°¾ëŠ” ê²Œì„ì„ ë§Œë“ ë‹¤. \n",
    "ex) A: ì‚°, B: ë°”ë‹¤, C: ë‚˜ë¬´, D: ë¬¼\n",
    "\n",
    "**<ì¶œë ¥ ì˜ˆì‹œ>**\n",
    "- ê´€ê³„ [ìˆ˜ê¸ : ì¶”ë½ = ëŒ€ì‚¬ê´€ : ?]\n",
    "- ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°€ì¥ ì í•©í•œ ë‹¨ì–´: ì ì…\n",
    "- ë‹¹ì‹ ì˜ ë‹µë³€ê³¼ ëª¨ë¸ ì˜ˆì¸¡ì˜ ìœ ì‚¬ë„: 0.34\n",
    "- ì•„ì‰½ë„¤ìš”. ë” ìƒê°í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9028b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from gensim.models.fasttext import load_facebook_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9f38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'cc.ko.300.bin'\n",
    "model = load_facebook_vectors(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a33be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_HANGUL_PATTERN = re.compile(r\"^[ê°€-í£]{2,6}$\")\n",
    "\n",
    "def get_korean_vocab(model, limit):\n",
    "    vocab = list(model.key_to_index.keys())[:limit]\n",
    "    korean_vocab = set()\n",
    "\n",
    "    for word in vocab:\n",
    "        # ì •ê·œì‹ìœ¼ë¡œ 2~6ê¸€ìì˜ í•œê¸€ ë‹¨ì–´ë§Œ í•„í„°ë§ (ì¡°ì‚¬, íŠ¹ìˆ˜ë¬¸ì ë“± ì œì™¸)\n",
    "        if _HANGUL_PATTERN.fullmatch(word):\n",
    "            korean_vocab.add(word)\n",
    "            \n",
    "    return list(korean_vocab)\n",
    "\n",
    "def generate_analogy_quiz(vocab, model, min_similarity=0.8):\n",
    "    while True:\n",
    "        try:\n",
    "            # 1. ëœë¤ ë‹¨ì–´ Aë¥¼ ì„ íƒ\n",
    "            a = random.choice(vocab)\n",
    "            \n",
    "            # 2. Aì™€ ìœ ì‚¬ë„ 0.8 ì´ìƒì¸ ë‹¨ì–´ Bë¥¼ ì°¾ìŒ (ìƒìœ„ 5ê°œ í›„ë³´ ì¤‘)\n",
    "            similar_words = model.most_similar(a, topn=5)\n",
    "            \n",
    "            # ì ì ˆí•œ B í›„ë³´ ì°¾ê¸°\n",
    "            b_candidates = [\n",
    "                word for word, sim in similar_words \n",
    "                if sim >= min_similarity and _HANGUL_PATTERN.fullmatch(word) and word != a\n",
    "            ]\n",
    "            \n",
    "            if not b_candidates:\n",
    "                continue\n",
    "            \n",
    "            b = random.choice(b_candidates)\n",
    "\n",
    "            # 3. A, Bì™€ëŠ” ë‹¤ë¥¸ Cë¥¼ ëœë¤í•˜ê²Œ ì„ íƒ\n",
    "            for _ in range(50):         \n",
    "                c = random.choice(vocab)\n",
    "                if c != a and c != b and model.similarity(a, c) < 0.6 and model.similarity(b, c) < 0.6:\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # 4. ëª¨ë¸ì„ ì´ìš©í•´ ì •ë‹µ Dë¥¼ ì˜ˆì¸¡\n",
    "            predicted_results = model.most_similar(positive=[b, c], negative=[a], topn=5)\n",
    "            \n",
    "            # 5. ì˜ˆì¸¡ëœ Dê°€ ë¬¸ì œë¡œ ì í•©í•œì§€ ê²€ì¦\n",
    "            for d_predicted, _ in predicted_results:\n",
    "                if (_HANGUL_PATTERN.fullmatch(d_predicted) and \n",
    "                    d_predicted not in [a, b, c]):\n",
    "                    return a, b, c, d_predicted\n",
    "                    \n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbdbd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(vocab, model):\n",
    "    # 1. ìœ íš¨í•œ ìœ ì¶” ë¬¸ì œ ìƒì„±\n",
    "    A, B, C, predicted_D = generate_analogy_quiz(vocab, model)\n",
    "\n",
    "    # 2. ì‚¬ìš©ìì—ê²Œ ë¬¸ì œ ì œì‹œ\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"ë‹¤ìŒ ê´€ê³„ë¥¼ ë³´ê³  '?'ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ë¥¼ ë§ì¶°ë³´ì„¸ìš”.\\n\")\n",
    "    print(f\"ê´€ê³„:  [{A} : {B}  =  {C} : ?]\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # 3. ì‚¬ìš©ì ë‹µë³€ ì…ë ¥\n",
    "    user_answer = input(\"ë‹¹ì‹ ì˜ ë‹µë³€: \").strip()\n",
    "\n",
    "    # 4. ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\n--- ê²°ê³¼ ---\")\n",
    "    print(f\"ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°€ì¥ ì í•©í•œ ë‹¨ì–´: {predicted_D}\")\n",
    "    print(f\"ë‹¹ì‹ ì˜ ë‹µë³€: {user_answer}\")\n",
    "\n",
    "    if user_answer == predicted_D:\n",
    "        print(\"\\nğŸ‰ ì •ë‹µì…ë‹ˆë‹¤! ëª¨ë¸ì˜ ì˜ˆì¸¡ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ìš”.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‹¨ì–´ê°€ ëª¨ë¸ ì–´íœ˜ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "        if user_answer in model:\n",
    "            similarity = model.similarity(user_answer, predicted_D)\n",
    "            print(f\"ë‹¹ì‹ ì˜ ë‹µë³€ê³¼ ëª¨ë¸ ì˜ˆì¸¡ì˜ ìœ ì‚¬ë„: {similarity:.2f}\")\n",
    "            \n",
    "            if similarity > 0.7:\n",
    "                print(\"ğŸ‘ ì •ë‹µì— ë§¤ìš° ê°€ê¹Œì›Œìš”! ì¢‹ì€ ë‹µë³€ì…ë‹ˆë‹¤.\")\n",
    "            elif similarity > 0.4:\n",
    "                print(\"ğŸ¤” ì•„ì‰½ë„¤ìš”. ë” ìƒê°í•´ë³´ì„¸ìš”.\")\n",
    "            else:\n",
    "                print(\"âŒ ë§ì´ ë²—ì–´ë‚œ ê²ƒ ê°™ì•„ìš”. ë‹¤ë¥¸ ë‹¨ì–´ë¥¼ ë– ì˜¬ë ¤ ë³´ì„¸ìš”.\")\n",
    "        else:\n",
    "            print(\"ì…ë ¥í•œ ë‹¨ì–´ëŠ” ëª¨ë¸ì˜ ì–´íœ˜ ì‚¬ì „ì— ì—†ì–´ìš”!\")\n",
    "            \n",
    "    except KeyError:\n",
    "         print(\"ì…ë ¥í•œ ë‹¨ì–´ëŠ” ëª¨ë¸ì˜ ì–´íœ˜ ì‚¬ì „ì— ì—†ì–´ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2526e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_vocab = get_korean_vocab(model, limit=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb763ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ë‹¤ìŒ ê´€ê³„ë¥¼ ë³´ê³  '?'ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ë¥¼ ë§ì¶°ë³´ì„¸ìš”.\n",
      "\n",
      "ê´€ê³„:  [ì´ë¥´ë˜ : ê°€ë¡œë˜  =  ìš´ë™í•˜ëŠ” : ?]\n",
      "==============================\n",
      "\n",
      "--- ê²°ê³¼ ---\n",
      "ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°€ì¥ ì í•©í•œ ë‹¨ì–´: ìš´ë™í•˜ê³ \n",
      "ë‹¹ì‹ ì˜ ë‹µë³€: ìš´ë™í•˜ë©°\n",
      "ë‹¹ì‹ ì˜ ë‹µë³€ê³¼ ëª¨ë¸ ì˜ˆì¸¡ì˜ ìœ ì‚¬ë„: 0.52\n",
      "ğŸ¤” ì•„ì‰½ë„¤ìš”. ë” ìƒê°í•´ë³´ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ê²Œì„ ì‹œì‘\n",
    "play_game(korean_vocab, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
